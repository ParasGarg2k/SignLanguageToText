# ğŸ¤Ÿ Sign Language to Text Conversion

This project aims to convert Sign Language gestures into text using a Convolutional Neural Network (CNN). It is built using Python, OpenCV, and TensorFlow, and features a real-time GUI using Tkinter to display detected characters, words, sentences, and word suggestions.

---

## ğŸ“Œ Introduction

Sign Language is a vital medium of communication for the deaf and hard-of-hearing communities. This system uses a camera-based approach to recognize ASL gestures and translate them into English text in real-time. It enhances accessibility and serves as an educational tool for learning ASL.

---

## ğŸ§  Model Flow
![Model Flow](images/modelflow.jpg)

---

## ğŸ” Application Flow
![Application Flow](images/signflow.jpg)


---

## ğŸ“‰ Confusion Matrix
![Confusion Matrix](images/conf.png)

---

## ğŸ“Š Performance Metrics

| Metric      | Value     |
|-------------|-----------|
| **Accuracy**| 98.22%    |
| **Precision** | 98.31% |
| **Recall**    | 98.22% |
| **F1 Score**  | 98.26% |


---

## ğŸš€ Technologies Used

- Python
- OpenCV
- TensorFlow / Keras
- Tkinter
- NumPy
- SpellChecker / Autocorrect
- PIL (Pillow)

---

## ğŸ–¥ï¸ Sample GUI Screenshot

![GUI Screenshot 1](images/gui2.png)
![GUI Screenshot 2](images/gui1.png)
---

## ğŸ“ Dataset

The model was trained on a custom dataset of American Sign Language (Aâ€“Z) images, including a "blank" class to indicate space between words.

---


## ğŸ“œ License

This project is open-source and available under the MIT License.

